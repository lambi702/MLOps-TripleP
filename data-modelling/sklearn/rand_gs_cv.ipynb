{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Grid Search for Hyperparameter Optimization of the Random Forest Regressor\n",
    "In this notebook, after we found out that the RF regressor is the best model for our dataset, we will perform a randomized grid search to find the best hyperparameters for the RF regressor. We will use the `RandomizedSearchCV` class from the `sklearn` library to perform the randomized grid search. We will use the `mean_squared_error` as the scoring metric for the grid search.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop printing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "\n",
    "# Test and train split and mean squared error metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Randomized search for hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/no_outliers.csv', sep=';', index_col=1)\n",
    "df = df.rename(columns={'Unnamed: 0': 'Timestamp'})\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "df['Month'] = df['Timestamp'].dt.month\n",
    "df['Day'] = df['Timestamp'].dt.day\n",
    "df['Hour'] = df['Timestamp'].dt.hour + df['Timestamp'].dt.minute / 60\n",
    "\n",
    "df = df.drop(columns=df.columns[:9])\n",
    "df = df.drop(columns=df.columns[1:10])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.drop(columns=df.columns[1:])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['Power_Total'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Train, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "features_val, features_test, target_val, target_test = train_test_split(features_temp, target_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print('Training features shape:', features_train.shape)\n",
    "print('Validation features shape:', features_val.shape)\n",
    "print('Testing features shape:', features_test.shape)\n",
    "print('Training target shape:', target_train.shape)\n",
    "print('Validation target shape:', target_val.shape)\n",
    "print('Testing target shape:', target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ravel the target arrays\n",
    "target_train = target_train.values.ravel()\n",
    "target_val = target_val.values.ravel()\n",
    "target_test = target_test.values.ravel()\n",
    "\n",
    "# Define the parameter grid with an expanded hyperparameter space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 2000),         # Increased number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],   # Number of features to consider at every split\n",
    "    'max_depth': [None] + list(randint(10, 200).rvs(50)),  # Expanded range for maximum depth\n",
    "    'min_samples_split': randint(2, 50),        # Increased range for minimum samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 50),         # Increased range for minimum samples required at each leaf node\n",
    "    'bootstrap': [True, False]                  # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "# Increase the number of iterations\n",
    "n_iter_search = 500\n",
    "\n",
    "# Increase the number of CV folds if computational resources allow\n",
    "cv_folds = 10  # You can increase this for more robust cross-validation\n",
    "\n",
    "# Instantiate a random forest regressor\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Create randomized search with adjusted parameters\n",
    "random_search = RandomizedSearchCV(estimator=rf_regressor, \n",
    "                                   param_distributions=param_dist, \n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=cv_folds, \n",
    "                                   verbose=2, \n",
    "                                   random_state=42, \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "random_search.fit(features_train, target_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_estimator = random_search.best_estimator_\n",
    "\n",
    "print('Best hyperparameters:', best_params)\n",
    "print('Best estimator:', best_estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
